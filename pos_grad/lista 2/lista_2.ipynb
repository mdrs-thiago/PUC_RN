{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "colab = True \n",
        "\n",
        "import os \n",
        "\n",
        "if colab:\n",
        "    !git clone https://github.com/mdrs-thiago/PUC_Redes_Neurais\n",
        "    os.chdir('/content/PUC_Redes_Neurais/pos_grad/lista 2')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_d3ZnDn5Rbll"
      },
      "source": [
        "# PUC-Rio \n",
        "## Departamento de Engenharia Elétrica\n",
        "## Trabalho 2 - Previsão de séries temporais\n",
        "\n",
        "Estudante:\n",
        "\n",
        "Base de dados:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHYb1u2lRblo"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "from torch.utils.data import WeightedRandomSampler, Dataset, DataLoader \n",
        "import torch.nn.functional as F\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import os\n",
        "\n",
        "from model_utils import train, train_multi_step_model\n",
        "\n",
        "from tqdm.notebook import tqdm\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preparação para a lista"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2W79BR_qDfKI"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, X_data, y_data):\n",
        "        self.X_data = X_data\n",
        "        self.y_data = y_data\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        return self.X_data[index], self.y_data[index]\n",
        "        \n",
        "    def __len__ (self):\n",
        "        return len(self.X_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "luN5IAD7DquQ"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork(torch.nn.Module):\n",
        "  '''\n",
        "  Objeto criado para facilitar o desenvolvimento dos scripts das aulas práticas.\n",
        "  Opção alternativa à criação externa fdo modelo. Basicamente serve como um \n",
        "  'agregador'  de trechos comuns para a criação do modelo. Por exemplo, ao invés\n",
        "  de gastar n+1 linhas para a criação de um modelo com n camadas, podemos criar \n",
        "  o mesmo modelo com apenas uma linha.\n",
        "  \n",
        "  Parâmetros de entrada: \n",
        "  - hidden_neurons: Lista com a quantidade de neurônios na camada escondida. \n",
        "  - hidden_activation: Função de ativação para cada camada escondida. Aceita \n",
        "  como parâmetro string ou lista. Caso o parâmetro receba string, então a mesma\n",
        "  função de ativação é utilizada para todas as camadas escondidas. Caso seja uma \n",
        "  lista, cada camada terá sua propria função de ativação definida pela lista.\n",
        "  - output_activation: Função de ativação para a camada de saída.\n",
        "  - lr: Taxa de aprendizado\n",
        "  - n_input: Tamanho do vetor de entrada.\n",
        "  - n_output: Saída do modelo.\n",
        "  '''\n",
        "  def __init__(self,hidden_neurons = 4, hidden_activation = 'relu', output_activation='softmax', lr = 0.05, n_input = 1, n_output = 1):\n",
        "    # create model\n",
        "    super(NeuralNetwork, self).__init__()\n",
        "\n",
        "    self.activations = {'relu': nn.ReLU(), 'sigmoid':nn.Sigmoid(), 'softmax':nn.Softmax()}\n",
        "\n",
        "    self.fc1 = nn.Linear(n_input, hidden_neurons)\n",
        "    self.ha = self.activations[hidden_activation]\n",
        "    self.fc2 = nn.Linear(hidden_neurons, n_output)\n",
        "    #self.out = self.activations[output_activation]\n",
        "    \n",
        "    #self.out = nn.Sigmoid() #Para o caso binário\n",
        "  def forward(self,x):\n",
        "    h = self.fc1(x)\n",
        "    h1 = self.ha(h) \n",
        "    y = self.fc2(h1) \n",
        "    #y = self.out(h2)\n",
        "    return y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZH4nTjcwRblp"
      },
      "outputs": [],
      "source": [
        "def transform_data(data, lag = 1, test_split = 0.1, normalize = True, category = 'binary'):\n",
        "    \n",
        "    '''\n",
        "    Função para transformação de dados para a 2ª Lista de exercícios.\n",
        "    A transformação de dados nesta etapa tem duas funções principais: a transformação da série em uma forma tabular para \n",
        "    o aprendizado de Redes Neurais e normalização dos dados.\n",
        "    Parâmetros de entrada:\n",
        "    - data: base de dados a ser ajeitado.\n",
        "    - test_split: propoporção da base de dados para teste. Caso seja um float entre 0 e 1, o valor é interpretado como proporção. \n",
        "    Caso seja um valor inteiro, é compreendido como o tempo reservado para generalização (e.g. lag = 12 reserva os 12 últimos \n",
        "    registros para o teste).\n",
        "    - normalize: normalização da série. Default True\n",
        "    - categ: string contendo a codificação a ser realizada para a variável exógena (no caso, o mês).\n",
        "\n",
        "    A função retorna dois dataframes, sendo o primeiro para treinamento e o segundo para generalização.\n",
        "    '''\n",
        "\n",
        "    global _min\n",
        "    global _max\n",
        "    \n",
        "    \n",
        "    data_values = data.values\n",
        "    \n",
        "    if 0 < test_split < 1.0:\n",
        "        l = data_values.shape[0]\n",
        "        train_values = data_values[:-int(test_split*l),0].reshape(-1,1)\n",
        "        test_values = data_values[-int(test_split*l):,0].reshape(-1,1)\n",
        "        train_idx = data_values[:-int(test_split*l),1].reshape(-1,1)\n",
        "        test_idx = data_values[-int(test_split*l):,1].reshape(-1,1)\n",
        "        \n",
        "    elif test_split > 1 and type(test_split) is int:\n",
        "\n",
        "        train_values = data_values[:-test_split,0].reshape(-1,1)\n",
        "        test_values = data_values[-test_split:,0].reshape(-1,1)\n",
        "        train_idx = data_values[:-test_split,1].reshape(-1,1)\n",
        "        test_idx = data_values[-test_split:,1].reshape(-1,1)\n",
        "        \n",
        "    else:\n",
        "        print('Test split not understood. Test split should be float between 0 and 1 or integer for index')\n",
        "    \n",
        "    assert test_values.shape[0] >= (lag)\n",
        "    \n",
        "    _min = np.min(train_values)\n",
        "    _max = np.max(train_values)\n",
        "    \n",
        "    if normalize:\n",
        "        \n",
        "        test_values = (test_values - _min)/(_max - _min)\n",
        "        train_values = (train_values - _min)/(_max - _min)\n",
        "        \n",
        "    train_data = np.zeros((train_values.shape[0] - (lag + 1), lag + 2))\n",
        "    test_data = np.zeros((test_values.shape[0], lag + 2))\n",
        "    \n",
        "    \n",
        "    all_data = np.vstack((train_values,test_values))\n",
        "    all_idx = np.vstack((train_idx,test_idx))\n",
        "\n",
        "    new_data = np.zeros((train_values.shape[0] - (lag + 1) + test_values.shape[0],lag + 2))\n",
        "    \n",
        "    \n",
        "    \n",
        "    for i in range(lag + 2):\n",
        "        new_data[:,i] = all_data[i:new_data.shape[0]+i,0]\n",
        "        \n",
        "\n",
        "    \n",
        "    if category == 'binary':\n",
        "        binary_rep = [np.binary_repr(z,width=4) for z in all_idx.astype('int').reshape(-1,)]\n",
        "        t0 = np.array([int(v) for s in binary_rep for v in s[0]])\n",
        "        t1 = np.array([int(v) for s in binary_rep for v in s[1]])\n",
        "        t2 = np.array([int(v) for s in binary_rep for v in s[2]])\n",
        "        t3 = np.array([int(v) for s in binary_rep for v in s[3]])\n",
        "        t = np.vstack((t0,t1,t2,t3)).T\n",
        "        t = t[-new_data.shape[0]:,:]\n",
        "        temp_idx = [f'month_{i}' for i in range(4)]\n",
        "        \n",
        "    elif category == '1toN':\n",
        "        pass\n",
        "    \n",
        "    else:\n",
        "        t = (all_idx - np.min(train_idx))/(np.max(train_idx) - np.min(train_idx))\n",
        "        t = t.reshape(-1,1)\n",
        "        t = t[-new_data.shape[0]:,:]\n",
        "        temp_idx = ['month']\n",
        "    \n",
        "    \n",
        "    new_data = np.hstack((t,new_data))\n",
        "    \n",
        "    train_data = new_data[:-test_values.shape[0],:]\n",
        "    test_data = new_data[-test_values.shape[0]:,:]\n",
        "    \n",
        "    \n",
        "    data_columns = [f'y(t{i})' if i < 0 else 'y(t)' if i == 0 else f'y(t+{i})' for i in range(-lag,2)] \n",
        "    temp_idx.extend(data_columns)\n",
        "    new_train_df = pd.DataFrame(train_data, columns=temp_idx)\n",
        "    new_test_df = pd.DataFrame(test_data, columns=temp_idx)\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    return new_train_df, new_test_df\n",
        "        \n",
        "    \n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jGxNjbU_Rblr"
      },
      "outputs": [],
      "source": [
        "dataset_name = 'microclima1'\n",
        "path = f'https://raw.githubusercontent.com/mdrs-thiago/PUC_Redes_Neurais/main/datasets/s_{dataset_name}.csv'\n",
        "raw_data = pd.read_csv(path)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "KCKBkpmqTjfU"
      },
      "source": [
        "## Parte I - Compreensão do problema\n",
        "\n",
        "Total: 3,0 pts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BP54d77HTnG0"
      },
      "source": [
        "#### 1.\tVisualize, em forma de gráfico, a dinâmica temporal da série escolhida. A série é adequada para a modelagem usando Redes Neurais? Caso não seja, que técnicas podem ser aplicadas para ajustar o comportamento da série?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "ndyb6iejTr1L",
        "outputId": "e73afdc3-022b-4068-f937-abd70796ba52"
      },
      "outputs": [],
      "source": [
        "raw_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-tyzdEUsTroC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5PLA6UnTm-o"
      },
      "source": [
        "#### 2.\tNesta 2ª lista de exercícios, usaremos uma variável exógena que representa o mês de previsão (i.e. no instante t+1). De que forma esta variável pode auxiliar na previsão da série temporal?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9k8ls62OUHFC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qan7fXx1Rblt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3. Observe que a base de dados não está em um formato adequado para o uso imediato de um modelo de Rede Neural para previsão de séries temporais. Descreva as etapas necessárias de transformação desta base de dados para que possamos utilizá-la no treinamento de uma MLP. Considere que os padrões de entrada (e saída) devem ser normalizados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "XNlVnXbmUNmF"
      },
      "source": [
        "## Parte 2 - Previsão one-step\n",
        "\n",
        "Total: 2,0 pts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<b> IMPORTANTE! </b> Este processo não é a previsão multi-step, conforme ensinado em sala de aula. \n",
        "Esta parte da lista é importante para evitar erros de avaliação para a previsão de séries temporais com um horizonte de previsão maior que 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6zqvC40URCh"
      },
      "source": [
        "#### 1.\tExecute o script para a previsão one-step. Avalie o resultado (conjunto de treinamento e teste) usando métricas apropriadas, como RMSE e MAE."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tp8MWFhSbrCS"
      },
      "outputs": [],
      "source": [
        "prev = 12\n",
        "train_val ,test_val = transform_data(raw_data,lag=12,test_split = prev,normalize=True,category='binary')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "QWasfnhDbxfM",
        "outputId": "a97fc6ff-1104-4ea1-b674-e11c2dfab9fe"
      },
      "outputs": [],
      "source": [
        "train_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "mqharkqDbxUk",
        "outputId": "e045afaf-5867-4da9-85a2-7cf46dc1db26"
      },
      "outputs": [],
      "source": [
        "test_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQsASJIfbqvz"
      },
      "outputs": [],
      "source": [
        "train_values = train_val.values\n",
        "\n",
        "X_train = train_values[:,:-1]\n",
        "y_train = train_values[:,-1]\n",
        "\n",
        "test_values = test_val.values\n",
        "X_test = test_values[:,:-1]\n",
        "y_test = test_values[:,-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_PHvaeoLTmk"
      },
      "outputs": [],
      "source": [
        "train_dataset = CustomDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train).float().unsqueeze(1))\n",
        "\n",
        "test_dataset = CustomDataset(torch.from_numpy(X_test).float(), torch.from_numpy(y_test).float().unsqueeze(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-zqOrtEZLTg1"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset,batch_size=batch_size)\n",
        "\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znvwxbUdcNze"
      },
      "outputs": [],
      "source": [
        "n_input = X_train.shape[1]\n",
        "n_output = 1\n",
        "hidden_neurons = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "repc4M4ScNwB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5Vg2c4KG0gO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "205c95d2c4514daf9bb625dbd8d8b90d",
            "5885dd2f223d496e922f2307456c3089",
            "7442bffb6eb84fc3abbf0a068c27bf7f",
            "29c00442e8fc442f942ba4d47ef88bb4",
            "ebe7941aa6e541029bf9fd2b656ef2e6",
            "2b993121246043db8d11f037eb005d6a",
            "f5b4195c7dfd4a16ac3d5f333a8dd561",
            "213aeafef243450c91e846f60daec0e2",
            "7ef292e1bed745e0a786035a63a736d0",
            "2249c9f23e5b4cbfb978f1f42c169a2d",
            "ae2a33d32d8a4dc3ba33fa28ad63b508"
          ]
        },
        "id": "Ju6gL6bVKJtL",
        "outputId": "c915efc1-ecb8-4a6b-8550-92e649f3064b"
      },
      "outputs": [],
      "source": [
        "model = NeuralNetwork(n_input = n_input, n_output=n_output, hidden_neurons = hidden_neurons, hidden_activation='sigmoid')\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "lr = 0.05\n",
        "epochs = 1000\n",
        "\n",
        "history, y_hat = train(model, train_loader, epochs, device, lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2X7TyC8EL033"
      },
      "outputs": [],
      "source": [
        "y_pred = model(torch.from_numpy(X_test).float())\n",
        "y_hat = y_pred.detach().numpy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "_NciXnnNcNuF",
        "outputId": "d427bd87-b767-4954-deab-8198a5d4c522"
      },
      "outputs": [],
      "source": [
        "orig_y_eval = y_test*(_max-_min) + _min\n",
        "orig_y_hat = y_hat*(_max-_min) + _min\n",
        "mae_error = mean_absolute_error(orig_y_eval, orig_y_hat)\n",
        "mse_error = mean_squared_error(orig_y_eval, orig_y_hat)\n",
        "\n",
        "plt.plot(orig_y_eval)\n",
        "plt.plot(orig_y_hat)\n",
        "plt.legend(['Original','Predicted'])\n",
        "\n",
        "print(f'Erro MSE = {round(mse_error,3)} \\nErro MAE = {round(mae_error,3)}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhTKjzt1UQ_l"
      },
      "source": [
        "#### 2.\tModifique a técnica de codificação mensal de ‘binário’ para ‘numérico’. Qual a mudança existente na arquitetura da Rede Neural? Analise o resultado (conjunto de treinamento e teste), usando as métricas adequadas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "peNfXlv1Rbl0"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_bSRsmjRbl2"
      },
      "source": [
        "## Parte 3 - Previsão multi-step\n",
        "\n",
        "Total: 5,0 pts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVaiSKqLUtCd"
      },
      "source": [
        "#### 1.\tEsquematize como você implementaria o processo de previsão multi-step. Descreva todos os passos necessários, e em seguida compare com o código fornecido para a previsão. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cD9-D2qDRbl3"
      },
      "outputs": [],
      "source": [
        "def multi_step(model, X_test, cod='numeric'):\n",
        "  y_result = []\n",
        "  X_t = np.copy(X_test[0])\n",
        "  for i in range(prev):\n",
        "      y_hat = model(torch.from_numpy(X_t).float())\n",
        "      \n",
        "      if cod == 'numeric':\n",
        "\n",
        "        #Ajeitando a codificação. Transformamos para o valor do mês e somamos 1 (para o próximo passo) e \n",
        "        #depois pegamos o resto da divisão por 12 (para que o mês fique sempre entre 0 e 11)\n",
        "        tmp = int(X_t[0] * 12 + 1) % 12\n",
        "        \n",
        "        #Alterando a variável mês\n",
        "        X_t[0] = tmp/12\n",
        "        \n",
        "        #Movendo todos os registros, 'deslizando a janela'\n",
        "        X_t[1:X_t.shape[0]-1] = X_t[2:]\n",
        "\n",
        "      elif cod == 'binary':\n",
        "        pass\n",
        "\n",
        "      else:\n",
        "        print('Erro de codificação.')\n",
        "        break\n",
        "      \n",
        "\n",
        "      X_t[-1] = y_hat\n",
        "      \n",
        "      y_result.append(y_hat[0].detach().numpy())\n",
        "\n",
        "\n",
        "  return np.array(y_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "M24dE6gbRbl3",
        "outputId": "ff88b23f-3c40-45ff-e4cd-b6be6c2d3f55"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lICkYvstVqm0"
      },
      "source": [
        "#### 2.\tFaça a previsão multi-step para o horizonte de previsão igual a 12. Perceba que o resultado da métrica é, geralmente, pior do que o apresentado para a previsão one-step. Por quê? É justo comparar o resultado deste item com o que foi apresentado anteriormente? Discuta. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_result = multi_step(model, X_test, cod='numeric')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-dIUX5-5WGhj"
      },
      "outputs": [],
      "source": [
        "orig_y_eval = y_test*(_max-_min) + _min\n",
        "orig_y_hat = y_result*(_max-_min) + _min\n",
        "mae_error = mean_absolute_error(orig_y_eval, orig_y_hat)\n",
        "mse_error = mean_squared_error(orig_y_eval, orig_y_hat)\n",
        "\n",
        "plt.plot(orig_y_eval)\n",
        "plt.plot(orig_y_hat)\n",
        "plt.legend(['Original','Predicted'])\n",
        "\n",
        "print(f'Erro MSE = {round(mse_error,3)} \\nErro MAE = {round(mae_error,3)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3h5tr49WJaL"
      },
      "source": [
        "#### 3.\tModifique o tamanho da janela de entrada do modelo. Analise os resultados, utilizando as métricas adequadas. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQBpyQrQWW-W"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDJa_TZyWZym"
      },
      "source": [
        "#### 4.\tModifique a topologia da rede para obter um melhor desempenho. Altere seus parâmetros (e.g. número de processadores na camada escondida, tipo de função na camada de saída) e avalie o desempenho."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bmp9ehcoWrJ8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 5. Modifique a função de previsão multi-step para permitir a codificação binária da variável mês. Em seguida, treine um modelo MLP usando a codificação binária para a variável exógena e faça a previsão multi-step e analise o resultado. \n",
        "\n",
        "OBS: Para este item, basta alterar a atualização da variável exógena na condição desejada (no caso, cod = 'binary')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "class_pratica2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "d044c6e0ce06759120adefce77398d00e1228e64d92f3f185fbd024a7701b8e0"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "205c95d2c4514daf9bb625dbd8d8b90d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5885dd2f223d496e922f2307456c3089",
              "IPY_MODEL_7442bffb6eb84fc3abbf0a068c27bf7f",
              "IPY_MODEL_29c00442e8fc442f942ba4d47ef88bb4"
            ],
            "layout": "IPY_MODEL_ebe7941aa6e541029bf9fd2b656ef2e6"
          }
        },
        "213aeafef243450c91e846f60daec0e2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2249c9f23e5b4cbfb978f1f42c169a2d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29c00442e8fc442f942ba4d47ef88bb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2249c9f23e5b4cbfb978f1f42c169a2d",
            "placeholder": "​",
            "style": "IPY_MODEL_ae2a33d32d8a4dc3ba33fa28ad63b508",
            "value": " 1500/1500 [00:05&lt;00:00, 267.85it/s]"
          }
        },
        "2b993121246043db8d11f037eb005d6a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5885dd2f223d496e922f2307456c3089": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b993121246043db8d11f037eb005d6a",
            "placeholder": "​",
            "style": "IPY_MODEL_f5b4195c7dfd4a16ac3d5f333a8dd561",
            "value": "100%"
          }
        },
        "7442bffb6eb84fc3abbf0a068c27bf7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_213aeafef243450c91e846f60daec0e2",
            "max": 1500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7ef292e1bed745e0a786035a63a736d0",
            "value": 1500
          }
        },
        "7ef292e1bed745e0a786035a63a736d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ae2a33d32d8a4dc3ba33fa28ad63b508": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ebe7941aa6e541029bf9fd2b656ef2e6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5b4195c7dfd4a16ac3d5f333a8dd561": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
